{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The Ishigami Function}$\n",
    "## Scalar-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_set = [100,1000,10000,100000]\n",
    "num_of_experiments_per_N = 50\n",
    "model_save_directory = 'data/ishigami/pick_freeze'\n",
    "model_save_name = f'N_set_{N_set}__numOfExperiments_{num_of_experiments_per_N}'.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"_\").replace(\" \",\"\")\n",
    "print(model_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishigami = model(model_type=\"ishigami\", vectSize=3, model_save_directory=model_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load an existing model (and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishigami = load_model(load_dir=f'{model_save_directory}/{model_save_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Pick-Freeze estimation for the ishigami function's main-effect Sobol' indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sobols(model=ishigami, N_set=N_set, itersPerN=num_of_experiments_per_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model and data if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishigami.save_model(file_name=model_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot(model=ishigami,\n",
    "            multi_experiment=True,\n",
    "            withOutliers=False,\n",
    "            withTrend=True,\n",
    "            no_title=True,\n",
    "            not_differences=False,\n",
    "            only_singulars=True,\n",
    "            base_fontsize=20,\n",
    "            save_fig=True,\n",
    "            save_directory='figs/ishigami/pick_freeze/scalar',\n",
    "            fig_name=f'ishigami_pickFreeze_convergence_{model_save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The Ishigami Function}$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import gen_uniform_1d_mesh_from_interval_and_resolution as genUniMesh\n",
    "from utils.other_utils import load_model, save_model, getSingletonIndexAsInt\n",
    "from glob import glob, escape\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aggr' sobols by calculating weights individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_domain = [-np.pi, -2.0]\n",
    "interval_domain = [-np.pi, np.pi]\n",
    "interval_mesh_resolution = 8\n",
    "ishigami_indicator_constraint_val = 3\n",
    "x3_as_mesh = genUniMesh(domain=interval_domain, mesh_resolution=interval_mesh_resolution)\n",
    "expNum_set = [1000]\n",
    "N_set = [1000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "save_dir = 'data/ishigami/indicator/scalar/mesh_x3_'\n",
    "save_dir += f'{list(np.round(interval_domain, 2))}'.replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "save_dir += f'_h_{interval_mesh_resolution}_constraint_{ishigami_indicator_constraint_val}'\n",
    "print(save_dir)\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "ishi_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_3 in x3_as_mesh:\n",
    "    t0 = time.time()\n",
    "    ishigami = nm.model(model_type='ishigami', vectSize=2)  \n",
    "    ishigami.specifyX3 = True\n",
    "    ishigami.x_3 = x_3\n",
    "    ishigami.ishigami_indicator = True\n",
    "    ishigami.constraintVal = ishigami_indicator_constraint_val\n",
    "    for _ in range(expNum_set[0]):\n",
    "        solvers.run_sobols(model=ishigami, N_set=N_set)\n",
    "    ishi_models_list.append(ishigami)\n",
    "    save_name = f\"x3_{np.round(x_3,2)}\".replace('.', '_').replace('-', 'neg')\n",
    "    save_model(model=ishigami, save_dir=save_dir, save_name=save_name)\n",
    "    t1 = time.time()\n",
    "    print(f\"Done for x_3: {x_3:0.2f} | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data (if not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishi_models_list = []\n",
    "files = glob(f\"{save_dir}/*.pkl\")\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    ishi_models_list.append(load_model(load_dir=file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate $S^{\\text{clos},Y}_A$ (Aggregate sobol indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_hat_list_all_exps = []\n",
    "for experim_i_key in range(expNum_set[0]):\n",
    "    V_hat_list_all_exps.append([np.mean([ishi_models_list[x3_idx].exprimentDataDict[0][experim_i_key]['indiv_output_variance'][f\"{N_set[-1]}\"]]) for x3_idx in range(len(ishi_models_list))])\n",
    "V_hat_list_all_exps = np.array(V_hat_list_all_exps)\n",
    "sum_all_v_hat_all_exps = np.sum(V_hat_list_all_exps,axis=1)\n",
    "c_j_list_all_exps = V_hat_list_all_exps / sum_all_v_hat_all_exps[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order_indices = ['01', '10']\n",
    "sobolVals_clos_aggr_adjusted = {k: [] for k in first_order_indices}\n",
    "num_of_experiments = len(ishi_models_list[0].exprimentDataDict[0])\n",
    "N_set = ishi_models_list[0].N_set       \n",
    "N_final = f\"{N_set[-1]}\" # can adjust so we can do for multiple N instead of just the N_final                              \n",
    "num_of_mesh_nodes = len(ishi_models_list)\n",
    "for sob_idx_str in first_order_indices:\n",
    "    # for each sample i, compute the weighted sum across models\n",
    "    for i in range(num_of_experiments):\n",
    "        weighted_sum = 0.0\n",
    "        for model_idx in range(num_of_mesh_nodes):\n",
    "            val = ishi_models_list[model_idx].exprimentDataDict[0][i]['sobolVals_clos'][N_final][sob_idx_str]\n",
    "            weighted_sum += val * c_j_list_all_exps[model_idx]\n",
    "        sobolVals_clos_aggr_adjusted[sob_idx_str].append(weighted_sum)\n",
    "values = np.array([np.asarray(sobolVals_clos_aggr_adjusted['01']).reshape(-1), np.asarray(sobolVals_clos_aggr_adjusted['10']).reshape(-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot individually calculated Aggr Sobol' Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from os import path, makedirs\n",
    "import re\n",
    "\n",
    "def plot_indiv_calculated_S_aggr(values,\n",
    "                                N_set,\n",
    "                                base_fontsize=20,\n",
    "                                save_fig=False,\n",
    "                                save_directory='',\n",
    "                                fig_name=''):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "    plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "    colors = [\"tomato\", \"royalblue\"]\n",
    "    base_fontsize = base_fontsize\n",
    "\n",
    "    for ax, val, color in zip(axes, values, colors):\n",
    "        box = ax.boxplot(val, patch_artist=True, showfliers=False)\n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "        for patch in box['boxes']:\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_edgecolor(\"black\")\n",
    "        for whisker in box['whiskers']:\n",
    "            whisker.set_color(color)\n",
    "        for cap in box['caps']:\n",
    "            cap.set_color(color)\n",
    "        for median in box['medians']:\n",
    "            median.set_color(\"black\")\n",
    "        ax.set_xticks(range(1, len(N_set) + 1))         \n",
    "        myXTicks = [rf\"$10^{int(np.log10(x))}$\" for x in N_set]\n",
    "        ax.set_xticklabels(myXTicks)\n",
    "        ax.tick_params(axis='x', labelsize=base_fontsize)\n",
    "        ax.tick_params(axis='y', labelsize=base_fontsize)\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_fontname('STIXGeneral')\n",
    "\n",
    "    fig.supylabel(r\"$\\hat{S}^{aggr}_{A}$\", fontsize=(base_fontsize+2))\n",
    "    fig.supxlabel(r\"Number of Samples, $N$\", fontsize=(base_fontsize+2), y=0.02)\n",
    "    box_handles = [mpatches.Patch(color=c, label=rf\"$U_{i+1}$\") for i, c in enumerate(colors)]\n",
    "    if base_fontsize <= 11:\n",
    "        vert_space_add_to_legend = 0.02\n",
    "    else:\n",
    "        vert_space_add_to_legend = (base_fontsize-14)/100\n",
    "    fig.legend(handles=box_handles,\n",
    "                loc=\"upper center\",\n",
    "                ncol=len(colors) + 1,\n",
    "                bbox_to_anchor=(0.5, 1.00+vert_space_add_to_legend),\n",
    "                fontsize=(base_fontsize+1),\n",
    "                frameon=False) \n",
    "    fig.tight_layout(rect=[0.01, 0, 1, 0.97])\n",
    "    if save_fig:\n",
    "        if save_directory == '':\n",
    "            save_directory = model.figsave_directory\n",
    "        else:\n",
    "            if not path.exists(save_directory):\n",
    "                makedirs(save_directory)\n",
    "        if fig_name == '':\n",
    "            fig_name = 'ishigami_pickfreeze.pdf'\n",
    "        plt.savefig(f\"{save_directory}/{fig_name}\", dpi=900, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "interval=re.search(r\"<(.*?)>\", files[0]).group(1)\n",
    "save_directory = 'figs/ishigami/pick_freeze/mesh/scalar'\n",
    "fig_name = f'ishigami_scalared_mesh_h_{len(files)-1}_interval_{interval}_Nexp_{num_of_experiments}_Nset_{N_set}.pdf'.replace(',', '_').replace('[','').replace(']','').replace(' ', '')\n",
    "print(fig_name)\n",
    "plot_indiv_calculated_S_aggr(values=values, \n",
    "                            N_set=N_set, \n",
    "                            base_fontsize=20,\n",
    "                            save_fig=True,\n",
    "                            save_directory=save_directory,\n",
    "                            fig_name=fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Aggr Sobols' Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis_keys = list(sobolVals_clos_aggr_adjusted_.keys())\n",
    "y_axis_values = list(sobolVals_clos_aggr_adjusted_.values())\n",
    "x_tick_pos = np.arange(len(x_axis_keys))\n",
    "plt.scatter(x_tick_pos, y_axis_values, color=\"blue\", s=80)\n",
    "plt.xticks(x_tick_pos, x_axis_keys)\n",
    "plt.xlabel(\"Input indices\")\n",
    "plt.ylabel(r\"$S^{aggr}_A$\")\n",
    "interval_as_str = f'{list(np.round(interval_domain, 2))}'.replace(\"np.float64(\", \"\").replace(\")\", \"\")\n",
    "plt.title(r\"Aggr. Sobols for Ishigami on interval $x_3\\in$\" + f\"{interval_as_str}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Individual Sobols' Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ishi_models_list:\n",
    "    plotter.plot(model=model,\n",
    "            multi_experiment=True,\n",
    "            withOutliers=False,\n",
    "            withTrend=False,\n",
    "            not_differences=True,\n",
    "            only_singulars=True,\n",
    "            save_fig=False)\n",
    "            # save_directory=f'kbsa/sobol_indicator_figs',\n",
    "            # fig_name=f'sobol_boxplots_x3_{x3}_N_[1e{int(np.log10(N_min))}:1e{int(np.log10(N_max))}]__indicator__NoOutliers__onlySingulars.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aggr' sobols via trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import gen_uniform_1d_mesh_from_interval_and_resolution as genUniMesh\n",
    "from utils.other_utils import load_model, save_model, getSingletonIndexAsInt\n",
    "from glob import glob, escape\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_domain = [-np.pi, np.pi]\n",
    "interval_mesh_resolution = 8\n",
    "ishigami_indicator_constraint_val = 3\n",
    "expNum_set = [50]\n",
    "N_set = [100,1000,10000,100000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "save_dir = 'data/ishigami/indicator/vector/'\n",
    "save_dir += f'{list(np.round(interval_domain,2))}_expNum_{expNum_set}_Nset_{N_set}'.replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "save_dir += f'_h_{interval_mesh_resolution}_constraint_{ishigami_indicator_constraint_val}'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "ishi_vect_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "ishigami_vect = nm.model(model_type='ishigami_vect', vectSize=2)\n",
    "ishigami_vect.ishigami_indicator = True\n",
    "ishigami_vect.constraintVal = ishigami_indicator_constraint_val\n",
    "ishigami_vect.meshInterval = interval_mesh_resolution\n",
    "ishigami_vect.set_uniform_1D_mesh(interval=interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=ishigami_vect, N_set=N_set, x_interval_of_interest=interval_domain)\n",
    "ishi_vect_models_list.append(ishigami_vect)\n",
    "save_name = \"ishigami_vect_model\"\n",
    "save_model(model=ishigami_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | t: {t1-t0:0.3f} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils import plotter\n",
    "from utils.other_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishi_vect_models_list = []\n",
    "files = glob(\"data/ishigami/indicator/vector/**/*.pkl\")\n",
    "for file in files:\n",
    "    if 'Nset' not in file:\n",
    "        continue\n",
    "    if '100000' not in file:\n",
    "        continue\n",
    "    print(file)\n",
    "    ishi_vect_models_list.append(load_model(load_dir=file))\n",
    "ishi_vect_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ishi_vect_models_list[1].ishi_interval = [-np.pi, -1.0]\n",
    "ishi_vect_models_list[2].ishi_interval = [-np.pi, np.pi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = 'figs/ishigami/pick_freeze/mesh/trace'\n",
    "for model in ishi_vect_models_list:\n",
    "    interval_domain = model.ishi_interval\n",
    "    interval_domain_trimmed = [round(x, 2) for x in interval_domain]\n",
    "    N_set = model.N_set\n",
    "    num_of_experiments = len(model.exprimentDataDict[str(interval_domain).replace(\" \", \"\")])\n",
    "    mesh_resolution = model.meshInterval\n",
    "    fig_name = f'ishigami_traced_mesh_h_{mesh_resolution}_interval_{interval_domain_trimmed}_Nexp_{num_of_experiments}_Nset_{N_set}'.replace(',', '_').replace('[','').replace(']','').replace(' ', '').replace('.','_').replace('-','neg') + '.pdf'\n",
    "    print(fig_name)\n",
    "    plotter.plot(model=model,\n",
    "                    N_set=N_set,\n",
    "                    plot_type='sobols',\n",
    "                    not_differences=True,\n",
    "                    only_singulars=True,\n",
    "                    interval_toggle=True,\n",
    "                    multi_experiment=True,\n",
    "                    which_interval=interval_domain, \n",
    "                    which_N=N_set[0],\n",
    "                    base_fontsize=20,# $$3vfdADFA,\n",
    "                    plot_which_sobols='closed_aggr',\n",
    "                    no_title=True,\n",
    "                    withTrend=True,\n",
    "                    save_fig=True,\n",
    "                    save_directory=save_directory,\n",
    "                    fig_name=fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The 1D-Diffusion Problem}$\n",
    "## Scalar-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import solvers\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these indices represent the h+1 many spatial-mesh-node-indices. Eg, index 1 translates to spatial point x=1/(h+1), and 32 to x=32/(h+1)\n",
    "evaluate_at_x_idx_list = [1,32,64] \n",
    "interval_mesh_resolution = 128\n",
    "diffuFen_sobol_vect_len = interval_mesh_resolution+1\n",
    "P = 3\n",
    "mu = 1\n",
    "std = 5\n",
    "indicator_constraint_val = 0.135\n",
    "indicator_toggle = False\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000]\n",
    "\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_toggle:\n",
    "    save_dir = f'data/1d_diffusion/pick_freeze/indicator/scalar/h_{interval_mesh_resolution}_max_N_{N_set[-1]}/'\n",
    "else:\n",
    "    save_dir = f'data/1d_diffusion/pick_freeze/non-indicator/scalar/h_{interval_mesh_resolution}_max_N_{N_set[-1]}/'\n",
    "print(save_dir)\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "diffuFen_models_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_idx in evaluate_at_x_idx_list:\n",
    "    save_name = f'1d_diffusion_xIdx_{x_idx}_xVal_{x_idx/129:.2f}_Nset_{N_set}'\n",
    "    save_name = save_name.replace(\"np.int64(\", \"\").replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "    if indicator_toggle:\n",
    "        save_name += f'_sobVectLen_{diffuFen_sobol_vect_len}_h_{interval_mesh_resolution}_constraint_{indicator_constraint_val}'\n",
    "    else:\n",
    "        save_name += f'_sobVectLen_{diffuFen_sobol_vect_len}_h_{interval_mesh_resolution}'\n",
    "    \n",
    "\n",
    "    t0 = time.time()\n",
    "    diffusion_1d = nm.model(model_type='diffusion_1D_both',\n",
    "                            P=P,\n",
    "                            mean=mu,\n",
    "                            std=std,\n",
    "                            meshInterval=interval_mesh_resolution,\n",
    "                            indicator_toggle=indicator_toggle,\n",
    "                            indicator_constraint_val=indicator_constraint_val,\n",
    "                            FEM_projection=False,\n",
    "                            model_save_directory=save_dir,\n",
    "                            model_save_name=save_name)\n",
    "    t0_inner, t1_inner = 0, 0\n",
    "    t0_outer = time.time()\n",
    "    for curr_exp in range(expNum_set[0]):\n",
    "        if curr_exp != 0:\n",
    "            stdout.write(f'\\r{save_name} | time_prev_experiment_#{curr_exp}: {t1_inner-t0_inner:0.3f} (s). Time so far: {t1_inner-t0_outer:0.3f} (s)')\n",
    "            stdout.flush()\n",
    "        t0_inner = time.time()\n",
    "        solvers.run_sobols(model=diffusion_1d, N_set=N_set, scalarDiffuIdx=x_idx)\n",
    "        t1_inner = time.time()\n",
    "    diffuFen_models_list.append(diffusion_1d)\n",
    "    print('\\n')\n",
    "    diffusion_1d.save_my_model()\n",
    "    # save_model(model=diffusion_1d, save_dir=save_dir, save_name=save_name)\n",
    "    t1 = time.time()\n",
    "    print(f\" -> {x_idx/129} done! Total time: {t1-t0:0.3f} (s).\\n---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils.other_utils import load_model\n",
    "\n",
    "diffuFen_models_list = []\n",
    "file_sup_dir = 'data/1d_diffusion/pick_freeze/non-indicator/scalar/h_128_max_N_1000'\n",
    "files = glob(f\"{file_sup_dir}/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    diffuFen_models_list.append(load_model(load_dir=file))\n",
    "diffuFen_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotter\n",
    "import re\n",
    "for file in files:\n",
    "    model = load_model(load_dir=file)\n",
    "# for model in diffuFen_models_list:\n",
    "    file_name = file[len(file_sup_dir)+1:-4]\n",
    "    print(file_name)\n",
    "    which_index = list(model.exprimentDataDict.keys())[0]\n",
    "    plotter.plot(model=model,\n",
    "                N_set=model.N_set,\n",
    "                only_singulars=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=False,\n",
    "                grid_toggle=True,\n",
    "                base_fontsize=22,\n",
    "                save_fig=True,\n",
    "                which_interval = None,\n",
    "                which_index = which_index,\n",
    "                save_directory='figs/1d_diffusion/vbsa/scalar',\n",
    "                fig_name=file_name)\n",
    "                # save_directory='figs/toy_2/pick_freeze/traced',\n",
    "                # fig_name=f'toy_2_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{The 1D-Diffusion Problem}$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import solvers\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_domain_list = [[0.0,1.0],[0.3,0.7],[0.45,0.55],[0.6,1.0]]\n",
    "# interval_domain_list = [[0.0,1.0],[0.45,0.55]]\n",
    "interval_domain_list = [[0.0,0.4], [0.6,1.0]]\n",
    "interval_mesh_resolution = 1024\n",
    "\n",
    "#this is set equal to mesh_interval when model is initiated. One can change it to maintain a specific resolution to sample equally from\n",
    "#if the projectOutputToCG option is chosen\n",
    "projectOutputToCG = False\n",
    "diffuFen_sobol_vect_len = interval_mesh_resolution+1\n",
    "P = 3\n",
    "mu = 1\n",
    "std = 5\n",
    "indicator_constraint_val = 0.135\n",
    "indicator_toggle = True\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100,1000,10000]\n",
    "\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "save_dir = f'data/1d_diffusion/pick_freeze/indicator/vector/h_{interval_mesh_resolution}_max_N_{N_set[-1]}/'\n",
    "if projectOutputToCG:\n",
    "    save_dir += f\"_projd_sobVectLec_{diffuFen_sobol_vect_len}\"\n",
    "print(save_dir)\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "diffuFen_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myT = (((2*20)+(14*20)+(155*20))*4)/(60*60)\n",
    "f\"{int(myT)}hr, {(myT-int(myT))*60:.0f}min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interval_domain in interval_domain_list:\n",
    "    save_name = f'1d_diffusion_{list(np.round(interval_domain,2))}_Nset_{N_set}'\n",
    "    save_name = save_name.replace(\"np.int64(\", \"\").replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "    if not projectOutputToCG:\n",
    "        save_name += f'_h_{interval_mesh_resolution}_constraint_{indicator_constraint_val}'\n",
    "    else:\n",
    "        save_name += f'_sobVectLen_{diffuFen_sobol_vect_len}_h_{interval_mesh_resolution}_constraint_{indicator_constraint_val}'\n",
    "\n",
    "    t0 = time.time()\n",
    "    diffusion_1d = nm.model(model_type='diffusion_1D_both',\n",
    "                            P=P,\n",
    "                            mean=mu,\n",
    "                            std=std,\n",
    "                            meshInterval=interval_mesh_resolution,\n",
    "                            indicator_toggle=indicator_toggle,\n",
    "                            indicator_constraint_val=indicator_constraint_val,\n",
    "                            FEM_projection=projectOutputToCG,\n",
    "                            model_save_directory=save_dir,\n",
    "                            model_save_name=save_name)\n",
    "    t0_inner, t1_inner = 0, 0\n",
    "    t0_outer = time.time()\n",
    "    for curr_exp in range(expNum_set[0]):\n",
    "        if curr_exp != 0:\n",
    "            stdout.write(f'\\r{save_name} | time_prev_experiment_#{curr_exp}: {t1_inner-t0_inner:0.3f} (s). Time so far: {t1_inner-t0_outer:0.3f} (s)')\n",
    "            stdout.flush()\n",
    "        t0_inner = time.time()\n",
    "        solvers.run_sobols(model=diffusion_1d, N_set=N_set, x_interval_of_interest=interval_domain)\n",
    "        t1_inner = time.time()\n",
    "    diffuFen_models_list.append(diffusion_1d)\n",
    "    print('\\n')\n",
    "    diffusion_1d.save_my_model()\n",
    "    # save_model(model=diffusion_1d, save_dir=save_dir, save_name=save_name)\n",
    "    t1 = time.time()\n",
    "    print(f\" -> {interval_domain} done! Total time: {t1-t0:0.3f} (s).\\n---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils.other_utils import load_model\n",
    "\n",
    "diffuFen_models_list = []\n",
    "file_sup_dir = 'data/1d_diffusion/pick_freeze/indicator/vector/h_1024_max_N_10000'\n",
    "files = glob(f\"{file_sup_dir}/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    diffuFen_models_list.append(load_model(load_dir=file))\n",
    "diffuFen_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotter\n",
    "import re\n",
    "for file in files:\n",
    "    model = load_model(load_dir=file)\n",
    "# for model in diffuFen_models_list:\n",
    "    if 10000 not in model.N_set:\n",
    "        continue\n",
    "    file_name = file[len(file_sup_dir)+1:-4]\n",
    "    print(file_name)\n",
    "    plotter.plot(model=model,\n",
    "                N_set=model.N_set,\n",
    "                only_singulars=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=False,\n",
    "                grid_toggle=True,\n",
    "                base_fontsize=22,\n",
    "                save_fig=True,\n",
    "                save_directory='figs/1d_diffusion/vbsa/traced',\n",
    "                fig_name=file_name)\n",
    "                # save_directory='figs/toy_2/pick_freeze/traced',\n",
    "                # fig_name=f'toy_2_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Affine Linear Function}\\;g_1$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import solvers\n",
    "from utils.other_utils import save_model\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_flag = True\n",
    "indicator_constraint_val = 3.75\n",
    "x_interval_domain = [0.25, 0.75]\n",
    "x_interval_mesh_resolution = 128\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000, 10000]\n",
    "# N_set = [10000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_flag:\n",
    "    save_dir = 'data/g_1/pick_freeze/indicator'\n",
    "else:\n",
    "    save_dir = 'data/g_1/pick_freeze/non_indicator'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "save_name = f\"toy_1_model_file__exprimentNum_{expNum_set[0]}__Nset_{N_set}__xInterval_{x_interval_domain}__h_{x_interval_mesh_resolution}\".replace(\"[\", \"\").replace(\"]\",'').replace(',', '_').replace(' ', '').replace('-','neg')\n",
    "if indicator_flag:\n",
    "    save_name += f\"__constraintVal_{indicator_constraint_val}\".replace('.', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_1_models_list = []\n",
    "t0 = time.time()\n",
    "toy_1_vect = nm.model(model_type='toy_1_vect', vectSize=3)\n",
    "toy_1_vect.indicator = indicator_flag\n",
    "toy_1_vect.constraintVal = indicator_constraint_val\n",
    "toy_1_vect.meshInterval = x_interval_mesh_resolution\n",
    "toy_1_vect.set_uniform_1D_mesh(interval=x_interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=toy_1_vect, N_set=N_set)\n",
    "toy_1_models_list.append(toy_1_vect)\n",
    "\n",
    "save_model(model=toy_1_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from utils.other_utils import load_model\n",
    "toy_1_models_list = []\n",
    "files = glob(\"data/g_1/pick_freeze/**/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    toy_1_models_list.append(load_model(load_dir=file))\n",
    "toy_1_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotter\n",
    "for model in toy_1_models_list:\n",
    "    plotter.plot(model=model,\n",
    "                multi_experiment=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=True,\n",
    "                no_title=True,\n",
    "                not_differences=True,\n",
    "                only_singulars=True,\n",
    "                base_fontsize=20,\n",
    "                save_fig=True,\n",
    "                only_aggr=True,\n",
    "                toy_1_or_2=True,\n",
    "                grid_toggle=True,\n",
    "                save_directory='figs/g_1/pick_freeze/traced',\n",
    "                fig_name=f'g_1_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Affine Linear Function}\\;g_2$ \n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import gen_uniform_1d_mesh_from_interval_and_resolution as genUniMesh\n",
    "from utils.other_utils import load_model, save_model, getSingletonIndexAsInt\n",
    "from glob import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs, path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_flag = True\n",
    "indicator_constraint_val = 5.25\n",
    "x_interval_domain = [0.25, 0.75]\n",
    "x_interval_mesh_resolution = 128\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000, 10000]\n",
    "# N_set = [10000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_flag:\n",
    "    save_dir = 'data/g_2/pick_freeze/indicator'\n",
    "else:\n",
    "    save_dir = 'data/g_2/pick_freeze/non_indicator'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "save_name = f\"g_2_model_file__exprimentNum_{expNum_set[0]}__Nset_{N_set}__xInterval_{x_interval_domain}__h_{x_interval_mesh_resolution}\".replace(\"[\", \"\").replace(\"]\",'').replace(',', '_').replace(' ', '').replace('-','neg')\n",
    "if indicator_flag:\n",
    "    save_name += f\"__constraintVal_{indicator_constraint_val}\".replace('.', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_2_models_list = []\n",
    "t0 = time.time()\n",
    "toy_2_vect = nm.model(model_type='toy_2_vect', vectSize=3)\n",
    "toy_2_vect.indicator = indicator_flag\n",
    "toy_2_vect.constraintVal = indicator_constraint_val\n",
    "toy_2_vect.meshInterval = x_interval_mesh_resolution\n",
    "toy_2_vect.set_uniform_1D_mesh(interval=x_interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=toy_2_vect, N_set=N_set)\n",
    "toy_2_models_list.append(toy_2_vect)\n",
    "save_model(model=toy_2_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_2_models_list = []\n",
    "files = glob(\"data/g_2/pick_freeze/**/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    toy_2_models_list.append(load_model(load_dir=file))\n",
    "toy_2_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in toy_2_models_list:\n",
    "    plotter.plot(model=model,\n",
    "                multi_experiment=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=True,\n",
    "                no_title=True,\n",
    "                not_differences=True,\n",
    "                only_singulars=True,\n",
    "                base_fontsize=20,\n",
    "                save_fig=True,\n",
    "                only_aggr=True,\n",
    "                toy_1_or_2=True,\n",
    "                grid_toggle=True,\n",
    "                save_directory='figs/g_2/pick_freeze/traced',\n",
    "                fig_name=f'g_2_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Nonlinear Problem}\\;g_3$\n",
    "## Vectorized-Set-Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\;\\mathbf{y} = (\\mathbb{1}_{\\{y_1\\leq 0\\}},...,\\mathbb{1}_{\\{y_{h+1}\\leq 0\\}})^T$,\n",
    "### $y_i=G(X,U)=u_1+u_1u_2+x^{(i)}_hu_1$, \n",
    "### $\\quad u_i\\sim \\mathbb{U}[ -1,1],\\; i\\in\\{1,2\\}$, \n",
    "### $\\quad x\\in[ -1,1] \\rightarrow x_h\\in\\{-1,-1+\\frac{1-(-1)}{h},...,1\\}\\;\\;h\\in\\mathbb{N}_{>0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import numeric_models as nm\n",
    "from utils import plotter, solvers\n",
    "from utils.other_utils import load_model, save_model\n",
    "from glob import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from os import makedirs, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating aggr' sobols via trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_domain = [-np.pi, -2.0]\n",
    "# interval_mesh_resolution = 8\n",
    "# ishigami_indicator_constraint_val = 3\n",
    "indicator_flag = True\n",
    "indicator_constraint_val = 0.0\n",
    "x_interval_domain = [-1.0, 1.0]\n",
    "x_interval_mesh_resolution = 128\n",
    "\n",
    "expNum_set = [20]\n",
    "N_set = [100, 1000, 10000]\n",
    "# N_set = [10000]\n",
    "N_min = np.min(N_set)\n",
    "N_max = np.max(N_set)\n",
    "if indicator_flag:\n",
    "    save_dir = 'data/g_3/pick_freeze/indicator'\n",
    "else:\n",
    "    save_dir = 'data/g_3/pick_freeze/non_indicator'\n",
    "# save_dir += f'{list(np.round(interval_domain,2))}'.replace(\"np.float64(\", \"\").replace(\")\", \"\").replace('.','_').replace(' ', '').replace('-','neg').replace('[','<').replace(']','>')\n",
    "# save_dir += f'_h_{interval_mesh_resolution}_constraint_{ishigami_indicator_constraint_val}'\n",
    "makedirs(save_dir, exist_ok=True)\n",
    "toy_model_vect_models_list = []\n",
    "save_name = f\"g_3_model_file__exprimentNum_{expNum_set[0]}__Nset_{N_set}__xInterval_{x_interval_domain}__h_{x_interval_mesh_resolution}\".replace(\"[\", \"\").replace(\"]\",'').replace(',', '_').replace(' ', '').replace('-','neg')\n",
    "if indicator_flag:\n",
    "    save_name += f\"__constraintVal_{indicator_constraint_val}\".replace('.', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "toy_model_vect = nm.model(model_type='toy_model_vect', vectSize=2)\n",
    "toy_model_vect.indicator = indicator_flag\n",
    "toy_model_vect.constraintVal = indicator_constraint_val\n",
    "toy_model_vect.meshInterval = x_interval_mesh_resolution\n",
    "toy_model_vect.set_uniform_1D_mesh(interval=x_interval_domain)\n",
    "\n",
    "for _ in range(expNum_set[0]):\n",
    "    solvers.run_sobols(model=toy_model_vect, N_set=N_set)\n",
    "toy_model_vect_models_list.append(toy_model_vect)\n",
    "\n",
    "\n",
    "save_model(model=toy_model_vect, save_dir=save_dir, save_name=save_name)\n",
    "t1 = time.time()\n",
    "print(f\"Done | T: {t1-t0:0.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model_vect_models_list = []\n",
    "files = glob(\"data/g_3/pick_freeze/**/*.pkl\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    toy_model_vect_models_list.append(load_model(load_dir=file))\n",
    "toy_model_vect_models_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, file_dir in zip(toy_model_vect_models_list, files):\n",
    "    fig_name = path.basename(file_dir).replace('.dill','.pdf')\n",
    "    fig_name = path.basename(file_dir).replace('.pkl','.pdf')\n",
    "    save_dir = path.dirname(file_dir)\n",
    "    model.specifyX3 = True\n",
    "    model.x_3 = 0\n",
    "    print(fig_name)\n",
    "    plotter.plot(model=model,\n",
    "                multi_experiment=True,\n",
    "                withOutliers=False,\n",
    "                withTrend=True,\n",
    "                no_title=True,\n",
    "                not_differences=True,\n",
    "                only_singulars=True,\n",
    "                base_fontsize=20,\n",
    "                save_fig=True,\n",
    "                only_aggr=True,\n",
    "                toy_1_or_2=False,\n",
    "                grid_toggle=True,\n",
    "                save_directory='figs/g_3/pick_freeze/traced',\n",
    "                fig_name=f'g_3_convergence_{save_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prototyping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage per 1 sample:       0.006 GiB\n",
      "Storage per 10000 samples: 60.000 GiB\n"
     ]
    }
   ],
   "source": [
    "U_dim = 5\n",
    "GiB_per_fem_folder = 0.5/1000\n",
    "#one for each input, and one for total agg Sobol of A (A^c) and one for closed agg Sobol of A\n",
    "#and need three of each output, for the vectPF algorithm \n",
    "GiB_per_one_full_data_sample = GiB_per_fem_folder * (U_dim * 2 + 2)\n",
    "sig_fig=len(str(GiB_per_one_full_data_sample)[2:])\n",
    "N = 10000\n",
    "statement_str_1 = f\"{'Storage per':<5} {1:<1}{' sample:':<{len('sample')}}\"\n",
    "statement_str_2 = f\"{'Storage per':<5} {N:<{len(str(N))}}{' samples:':<{len('samples')}}\"\n",
    "statement_val_2 = f\"{N*GiB_per_one_full_data_sample:>.{sig_fig}f}\"\n",
    "align_w = len(statement_val_2) + (len(statement_str_2) - len(statement_str_1))\n",
    "statement = f\"\\\n",
    "{statement_str_1} {GiB_per_one_full_data_sample:>{align_w}.{sig_fig}f} {'GiB':>3}\\n\\\n",
    "{statement_str_2} {statement_val_2} {'GiB':>3}\"\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GiB_per_fem_folder*50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numeric_models.numeric_models_utils import generate_data\n",
    "import numpy as np\n",
    "\n",
    "u_A = generate_data('log_uniform', min_u=5.5e11, max_u=1.5e12, size=3)\n",
    "u_E = generate_data('log_uniform', min_u=1.5e3, max_u=9.5e3, size=3)\n",
    "u_T_i = generate_data('uniform', min_u=850, max_u=1000, size=3)\n",
    "u_T_o = generate_data('uniform', min_u=200, max_u=400, size=3)\n",
    "u_phi = generate_data('uniform', min_u=0.5, max_u=1.5, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([u_A, u_E, u_T_i, u_T_o, u_phi])\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.15252861e+11 5.58438575e+03 9.47043546e+02 2.39255229e+02\n",
      " 5.08284904e-01]\n",
      "[1.40459486e+12 1.95914450e+03 8.56424820e+02 2.73950368e+02\n",
      " 1.17976310e+00]\n",
      "[6.40725843e+11 8.08490321e+03 9.40537517e+02 2.32377236e+02\n",
      " 1.32944526e+00]\n"
     ]
    }
   ],
   "source": [
    "u_I = u[:,0]\n",
    "u_II = u[:,1]\n",
    "u_III = u[:,2]\n",
    "print(u_I) # no touch\n",
    "print(u_II) # used for combin, A\n",
    "print(u_III) # used for combin, A^c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.15252861e+11, 5.58438575e+03, 9.47043546e+02, 2.39255229e+02,\n",
       "       5.08284904e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([u_A[0], u_E[0], u_T_i[0], u_T_o[0], u_phi[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40459486e+12, 1.95914450e+03, 9.40537517e+02, 2.32377236e+02,\n",
       "       1.17976310e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_tilde = np.where(np.array(list(\"11001\"), dtype=np.int8) == 1, u_II, u_III)\n",
    "u_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/set_kbsa/lib/python3.10/site-packages/ufl/__init__.py:250: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started work. Rank 0 - A_str - I - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Work done! Rank 0 - A_str - I - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Started work. Rank 0 - A_str - II - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Work done! Rank 0 - A_str - II - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Started work. Rank 0 - A_str - 01111 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Work done! Rank 0 - A_str - 01111 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Started work. Rank 0 - A_str - 10111 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Work done! Rank 0 - A_str - 10111 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Started work. Rank 0 - A_str - 11011 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Work done! Rank 0 - A_str - 11011 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Started work. Rank 0 - A_str - 11101 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Work done! Rank 0 - A_str - 11101 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Started work. Rank 0 - A_str - 11110 - local uid 72d9a09662084f06b83a182d1365eeaa\n",
      "Work done! Rank 0 - A_str - 11110 - local uid 72d9a09662084f06b83a182d1365eeaa\n"
     ]
    }
   ],
   "source": [
    "from data_generation_scripts.cdr_vecSob import cdr_vecSob_experiment\n",
    "from auxiliary_utils.io_management import make_directory\n",
    "from auxiliary_utils.index_management import order_r_idx_as_onehot_generator\n",
    "cdr_t_end = 0.01\n",
    "cdr_num_steps = 1\n",
    "cdr_params = {'mesh_2D_dir': 'data/CDR/mesh_save_dir/rectangle.xdmf', \n",
    "                't_end': cdr_t_end, #in seconds\n",
    "                'num_steps': cdr_num_steps, #time steps, in t_end/num_steps increments, e.g., 100 steps for 0.01 t_end is 0.0001s, 0.1ms\n",
    "                'return_bool': False,\n",
    "                'mesh_steps': 0.025,\n",
    "                'g_ineq_c': {'fuel': 0.02, 'oxygen': 0.14, 'product': 0.014, 'temp': 900}}\n",
    "parent_directory, parent_uid = make_directory(directory='data/experiment_data/cdr/vecSob',\n",
    "                                                    with_uid=True,\n",
    "                                                    with_datetime=True, \n",
    "                                                    return_new_directory=True, \n",
    "                                                    return_uid=True)\n",
    "index_set = [a for a in order_r_idx_as_onehot_generator(4,5)]\n",
    "cdr_vecSob_experiment(index_set_to_calculate=index_set, \n",
    "                    cdr_params=cdr_params,\n",
    "                    mpi_rank=0,\n",
    "                    parent_directory=parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01111', '10111', '11011', '11101', '11110', '00001', '00010', '00100', '01000', '10000']\n"
     ]
    }
   ],
   "source": [
    "c = [idx for idx in order_r_idx_as_onehot_generator(4,5)] + [idx for idx in order_r_idx_as_onehot_generator(1,5)]\n",
    "print((c))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0. ]\n",
      " [0.  0.5]\n",
      " [1.  0. ]\n",
      " [1.  0.5]]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from numpy import (linspace as np_linspace, array as np_array)\n",
    "test_domain = np_array([[0,1],[0,0.5]])\n",
    "d = test_domain.shape[0]\n",
    "h = 2\n",
    "# axes = \n",
    "grid_points = np_array(list(product(*[np_linspace(test_domain[i,0], test_domain[i,1], h) for i in range(d)])))\n",
    "print(grid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 1.]), array([0. , 0.5])]\n",
      "[[0.  0. ]\n",
      " [0.  0.5]\n",
      " [1.  0. ]\n",
      " [1.  0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(axes)\n",
    "print(grid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/set_kbsa/lib/python3.10/site-packages/ufl/__init__.py:250: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "from auxiliary_utils.io_management import load_mesh\n",
    "from numpy.linalg import norm as np_norm\n",
    "from scipy.spatial import cKDTree\n",
    "from dolfin.cpp.mesh import edges\n",
    "\n",
    "mesh = load_mesh()\n",
    "min_cell_diam = mesh.hmin() #minsup_{cells \\in mesh}(cell_diameter), cell diameter wrt all cells in mesh\n",
    "\n",
    "coords = mesh.coordinates()\n",
    "\n",
    "tree = cKDTree(coords)\n",
    "dists, _ = tree.query(coords, k=2)   # self + nearest neighbor\n",
    "min_vert_to_vert = float(dists[:, 1].min()) #minimum vertex-to-vertex distance (not necessarily an edge in the mesh)\n",
    "\n",
    "min_edge = min(np_norm(coords[e.entities(0)[0]] - coords[e.entities(0)[1]]) for e in edges(mesh)) #length of the smallest edge in the mesh\n",
    "\n",
    "smallest_mesh_distances_list = [min_cell_diam, min_vert_to_vert, min_edge]\n",
    "print(int(2/min(smallest_mesh_distances_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 5\n",
    "A = np.array([[1],[2]])\n",
    "B = np.ones(shape=(n,1), dtype=np.uint8)\n",
    "C = B*A.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Time: 1.61593\n",
      "Mean Time: 0.49798\n",
      "T_B: 0.3280496299109204, Time: 1.35330\n",
      "T_C: 0.3280496299110174, Time: 12.98471\n",
      "9.697798120100742e-14\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "h = 10000\n",
    "t0_rand = time.time_ns()\n",
    "y = np.random.uniform(1, 5, size=(3, n, h))\n",
    "t0_A = time.time_ns()\n",
    "y_bar = np.mean(y, axis=1)\n",
    "# T_A = 0\n",
    "# for i in range(n):\n",
    "#     for j in range(h):\n",
    "#         T_A += (y[0,i,j] - y_bar[1,j])*(y[2,i,j]-y_bar[2,j])\n",
    "# T_A = T_A/(n-1)\n",
    "t1_A = time.time_ns()\n",
    "\n",
    "# y_bar_II = np.asarray(y_bar[1]).ravel()  #(h,)\n",
    "# y_bar_tilde = np.asarray(y_bar[2]).ravel() #(h,)\n",
    "y_II_bar = np.asarray(y_bar[1], dtype=np.float64).reshape(1, -1)\n",
    "y_tilde_bar = np.asarray(y_bar[2], dtype=np.float64).reshape(1, -1)\n",
    "y_I_centered_II = np.asarray(y[0], dtype=np.float64) - y_II_bar\n",
    "y_tilde_centered_tilde = np.asarray(y[2], dtype=np.float64) - y_tilde_bar\n",
    "T_B = np.einsum('ij,ij->', y_I_centered_II, y_tilde_centered_tilde, optimize=True) / (n - 1)\n",
    "t1_B = time.time_ns()\n",
    "\n",
    "T_C = ((y[0] - y_bar[1]) * (y[2] - y_bar[2])).sum() / (n - 1) \n",
    "t1_C = time.time_ns()\n",
    "\n",
    "print(f\"Sampling Time: {(t0_A-t0_rand)*10**-9:0.5f}\")\n",
    "print(f\"Mean Time: {(t1_A-t0_A)*10**-9:0.5f}\")\n",
    "print(f\"T_B: {T_B}, Time: {(t1_B-t1_A)*10**-9:0.5f}\")\n",
    "print(f\"T_C: {T_C}, Time: {(t1_C-t1_B)*10**-9:0.5f}\")\n",
    "print((np.abs(T_B-T_C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_var_A: 13333.675336629214, Time: 0.46917\n",
      "T_var_B: 13333.675336629241, Time: 0.10882\n",
      "2.7284841053187847e-11\n"
     ]
    }
   ],
   "source": [
    "t0_A = time.time_ns()\n",
    "T_var_A = ((y[0] - y_bar[0])**2).sum() / (n-1)\n",
    "t1_A = time.time_ns()\n",
    "y_I = np.asarray(y[0], dtype=np.float64)\n",
    "y_bar_I = np.asarray(y_bar[0], dtype=np.float64).reshape(1, -1)\n",
    "y_I_centered_I = y_I - y_bar_I\n",
    "T_var_B = np.einsum('ij,ij->', y_I_centered_I, y_I_centered_I, optimize=True) / (n - 1)\n",
    "\n",
    "t1_B = time.time_ns()\n",
    "print(f\"T_var_A: {T_var_A}, Time: {(t1_A-t0_A)*10**-9:0.5f}\")\n",
    "print(f\"T_var_B: {T_var_B}, Time: {(t1_B-t1_A)*10**-9:0.5f}\")\n",
    "print((np.abs(T_var_A-T_var_B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "set_kbsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
